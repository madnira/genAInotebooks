{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymilvus import MilvusClient  #Defingin a milvus client to create a local DB\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a object for Milvus Client; in our case it is RAGclient referrgin to the local db path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGclient = MilvusClient(\"../DB/RAG.db\")     # creating a local db file for milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a collection in the Milvus DB object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGclient.create_collection(\n",
    "    collection_name= \"rag_collection\",\n",
    "    primary_field_name= \"ID\",\n",
    "    vector_field_name= \"ContentVector\",\n",
    "    dimension=768,  # The vectors we will use in this demo has 768 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the collections in the client object defined above; in this case it is by the name RAGclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAGclient.drop_collection(collection_name=\"rag_collection\")\n",
    "res = RAGclient.list_collections() \n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the count of existing rows from the db. (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RAGclient.get_collection_stats(collection_name=\"rag_collection\")\n",
    "rows = rc['row_count']\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uplaod the embeddgings in the local Milvus db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_embeddinf_in_db(embedding_file, collection_name):\n",
    "      # Load data from JSON file\n",
    "  with open(os.path.join(dir, embedding_file), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    insert_result = RAGclient.insert(collection_name=collection_name, data=data)\n",
    "  \n",
    "  return insert_result\n",
    "\n",
    "#Usage \n",
    "dir = \"../jsonfiles/\" # Local path where the embeddign json files are saved\n",
    "embedding_file = \"data_with_embeddings.json\"  # Replace with the embedding JSON file\n",
    "collection_name = \"rag_collection\"\n",
    "\n",
    "upload_embeddinf_in_db(embedding_file, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querrying the RAG_Collection DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-mpnet-base-v2\"    # Using open source model from Hugging Face\n",
    "modelPath = f\"../model/{model_name}\"      # Create a local path to store th model\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(modelPath)   # Saving the HF model in local path so that it can be used offline as well for generating embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the saved model from the local path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SentenceTransformer model fromthe local path\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "modelPath = f\"../model/{model_name}\" \n",
    "\n",
    "model = SentenceTransformer(modelPath)\n",
    "print(f\"Model loaded - \",model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a question from the user with a input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettign the query as an input from the user and create embedding of the query\n",
    "q = input()\n",
    "question = [q]\n",
    "#question = [\"What is the websote of thames water?\"]\n",
    "query_vector = model.encode(question).tolist()\n",
    "\n",
    "search_result = RAGclient.search(\n",
    "    collection_name=\"rag_collection\",  # target collection\n",
    "    data=query_vector,  # query vector from the user asked question\n",
    "    limit=3,  # returning the top 3 entities\n",
    "    output_fields=[\"Title\", \"Content\"],  # specifies fields to be returned\n",
    ")\n",
    "\n",
    "search_result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the citation for the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit1 = search_result[0][0][\"entity\"][\"Title\"]\n",
    "cit2 = search_result[0][1][\"entity\"][\"Title\"]\n",
    "\n",
    "print(f\"citation1: {cit1} \\ncitation2: {cit2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the top 2 chunks returned by the index to create a single content to pass on to the LLM for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = search_result[0][0][\"entity\"][\"Content\"]\n",
    "chunk2 = search_result[0][1][\"entity\"][\"Content\"]\n",
    "comprehensive_chunk = chunk1+chunk2\n",
    "print(comprehensive_chunk)\n",
    "#print(chunk1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
